package main

import (
	"bytes"
	"context"
	"fmt"
	"io"
	"net/http"
	"os"
	"path/filepath"
	"sort"
	"strings"
	"sync"
	"time"

	"github.com/bmatcuk/doublestar/v4"
	"gitlab.com/tozd/go/errors"
)

var (
	processedFiles sync.Map
	loggerMu       sync.Mutex
)

func logFileOperation(logger *Logger, file string, status FileStatus, replacementCount int) {
	if _, loaded := processedFiles.LoadOrStore(file, true); !loaded {
		loggerMu.Lock()
		defer loggerMu.Unlock()
		var replacements *int
		if replacementCount > 0 {
			replacements = &replacementCount
		}
		op := FileInfo{
			Name:         file,
			Status:       status,
			IsSpecial:    strings.HasSuffix(file, ".copyrc.lock"),
			IsUntracked:  !strings.HasSuffix(file, ".copyrc.lock") && strings.HasSuffix(file, ".go") && !strings.HasSuffix(file, ".copy.go") && file != "embed.gen.go",
			Replacements: replacements,
		}
		logger.AddFileOperation(op)
	}
}

// üßπ Clean destination directory
func cleanDestination(status *StatusFile, destPath string) error {
	logger := NewLogger(os.Stdout)

	for _, entry := range status.CoppiedFiles {
		logger.Operation(fmt.Sprintf("Removing %s", entry.File))
		if err := os.Remove(filepath.Join(destPath, entry.File)); err != nil {
			return errors.Errorf("removing file: %w", err)
		}
	}

	for _, entry := range status.GeneratedFiles {
		logger.Operation(fmt.Sprintf("Removing %s", entry.File))
		if err := os.Remove(filepath.Join(destPath, entry.File)); err != nil {
			return errors.Errorf("removing file: %w", err)
		}
	}

	logger.Operation("Removing status file")
	if err := os.Remove(filepath.Join(destPath, ".copyrc.lock")); err != nil {
		if !os.IsNotExist(err) {
			return errors.Errorf("removing status file: %w", err)
		}
	}

	return nil
}

func processFile(ctx context.Context, provider RepoProvider, cfg *Config, file, commitHash string, status *StatusFile, mu *sync.Mutex) error {
	logger := NewLogger(os.Stdout)

	if cfg.ArchiveArgs != nil {
		if cfg.ProviderArgs.Path != "" {
			return errors.New("path is not supported in tarball mode")
		}

		// Ensure cache directory exists
		repoName := filepath.Base(cfg.ProviderArgs.Repo)
		repoDir := filepath.Join(cfg.DestPath, repoName)
		if err := os.MkdirAll(repoDir, 0755); err != nil {
			return errors.Errorf("creating repo directory: %w", err)
		}

		// Download tarball
		data, err := GetFileFromTarball(ctx, provider, cfg.ProviderArgs)
		if err != nil {
			return errors.Errorf("getting file from tarball: %w", err)
		}
		tarballPath := filepath.Join(repoDir, repoName+".tar.gz")

		preTarball, err := os.ReadFile(tarballPath)
		if err != nil && !os.IsNotExist(err) {
			return errors.Errorf("reading existing tarball: %w", err)
		}

		// Save tarball
		if err := os.WriteFile(tarballPath, data, 0644); err != nil {
			return errors.Errorf("writing tarball: %w", err)
		}

		sourceInfo, err := provider.GetSourceInfo(ctx, cfg.ProviderArgs, commitHash)
		if err != nil {
			return errors.Errorf("getting source info: %w", err)
		}

		permalink, err := provider.GetArchiveUrl(ctx, cfg.ProviderArgs)
		if err != nil {
			return errors.Errorf("getting permalink: %w", err)
		}

		entry := StatusEntry{
			File:      repoName + ".tar.gz",
			Source:    sourceInfo,
			Permalink: permalink,
			Changes:   []string{},
		}

		mu.Lock()
		_, hasOldStatus := status.CoppiedFiles[entry.File]
		mu.Unlock()

		if len(preTarball) > 0 && bytes.Equal(preTarball, data) && hasOldStatus {
			mu.Lock()
			entry.LastUpdated = status.CoppiedFiles[entry.File].LastUpdated
			mu.Unlock()
			logFileOperation(logger, entry.File, RegularFile, 0)
		} else {
			entry.LastUpdated = time.Now().UTC()
			logFileOperation(logger, entry.File, UpdatedFile, 0)
		}

		if cfg.ArchiveArgs.GoEmbed {
			// Create embed.go file
			pkgName := strings.ReplaceAll(repoName, "-", "")
			embedPath := filepath.Join(repoDir, "embed.gen.go")
			var buf bytes.Buffer

			fmt.Fprintf(&buf, "// üì¶ generated by copyrc. DO NOT EDIT.\n")
			fmt.Fprintf(&buf, "// ‚ÑπÔ∏è see .copyrc.lock for more details.\n\n")
			fmt.Fprintf(&buf, "package %s\n\n", pkgName)
			fmt.Fprintf(&buf, "import _ \"embed\"\n\n")
			fmt.Fprintf(&buf, "//go:embed %s.tar.gz\n", repoName)
			fmt.Fprintf(&buf, "var Data []byte\n\n")
			fmt.Fprintf(&buf, "// Metadata about the downloaded repository\n")
			fmt.Fprintf(&buf, "var (\n")
			fmt.Fprintf(&buf, "\tRef        = %q\n", cfg.ProviderArgs.Ref)
			fmt.Fprintf(&buf, "\tCommit     = %q\n", commitHash)
			fmt.Fprintf(&buf, "\tRepository = %q\n", cfg.ProviderArgs.Repo)
			fmt.Fprintf(&buf, "\tPermalink  = %q\n", permalink)
			fmt.Fprintf(&buf, "\tDownloaded = %q\n", entry.LastUpdated.Format(time.RFC3339))
			fmt.Fprintf(&buf, ")\n")

			mu.Lock()
			_, hasOldStatus := status.GeneratedFiles["embed.gen.go"]
			mu.Unlock()

			byt := buf.Bytes()
			if hasOldStatus {
				curr, err := os.ReadFile(embedPath)
				if err != nil && !os.IsNotExist(err) {
					return errors.Errorf("reading existing embed.gen.go: %w", err)
				}
				if len(curr) > 0 && bytes.Equal(curr, byt) {
					logFileOperation(logger, "embed.gen.go", RegularFile, 0)
				} else {
					logFileOperation(logger, "embed.gen.go", UpdatedFile, 0)
					if err := os.WriteFile(embedPath, byt, 0644); err != nil {
						return errors.Errorf("writing embed.gen.go: %w", err)
					}
				}
			} else {
				logFileOperation(logger, "embed.gen.go", NewFile, 0)
				if err := os.WriteFile(embedPath, byt, 0644); err != nil {
					return errors.Errorf("writing embed.gen.go: %w", err)
				}
			}

			entry.Changes = []string{"generated embed.gen.go file"}
			mu.Lock()
			status.GeneratedFiles["embed.gen.go"] = GeneratedFileEntry{
				File:        "embed.gen.go",
				LastUpdated: entry.LastUpdated,
			}
			mu.Unlock()
		}

		// just in case
		mu.Lock()
		delete(status.GeneratedFiles, entry.File)
		status.CoppiedFiles[entry.File] = entry
		mu.Unlock()

		return nil
	}

	if cfg.CopyArgs == nil {
		return errors.New("copy args are required")
	}

	sourceInfo, err := provider.GetSourceInfo(ctx, cfg.ProviderArgs, commitHash)
	if err != nil {
		return errors.Errorf("getting source info: %w", err)
	}

	permalink, err := provider.GetPermalink(ctx, cfg.ProviderArgs, commitHash, file)
	if err != nil {
		return errors.Errorf("getting permalink: %w", err)
	}

	var contentz []byte
	if strings.HasPrefix(permalink, "file://") {
		contentz, err = os.ReadFile(strings.TrimPrefix(permalink, "file://"))
		if err != nil {
			return errors.Errorf("reading file: %w", err)
		}
	} else {
		req, err := http.NewRequestWithContext(ctx, "GET", permalink, nil)
		if err != nil {
			return errors.Errorf("creating request: %w", err)
		}

		resp, err := http.DefaultClient.Do(req)
		if err != nil {
			return errors.Errorf("downloading file: %w", err)
		}
		defer resp.Body.Close()

		if resp.StatusCode != http.StatusOK {
			return errors.Errorf("downloading file: %s", resp.Status)
		}

		contentz, err = io.ReadAll(resp.Body)
		if err != nil {
			return errors.Errorf("reading file: %w", err)
		}
	}

	// Get base name and extension
	ext := filepath.Ext(file)
	base := strings.TrimSuffix(filepath.Base(file), ext)

	// Create status entry
	entry := StatusEntry{
		File:        base + ".copy" + ext,
		Source:      sourceInfo,
		Permalink:   permalink,
		LastUpdated: time.Now().UTC(),
	}

	// Process content
	var buf bytes.Buffer

	// Add file header based on extension
	switch ext {
	case ".go", ".js", ".ts", ".jsx", ".tsx", ".cpp", ".c", ".h", ".hpp", ".java", ".scala", ".rs", ".php", "jsonc":
		fmt.Fprintf(&buf, "// üì¶ generated by copyrc. DO NOT EDIT.\n")
		fmt.Fprintf(&buf, "// üîó source: %s\n", permalink)
		fmt.Fprintf(&buf, "// ‚ÑπÔ∏è see .copyrc.lock for more details.\n\n")
	case ".py", ".rb", ".pl", ".sh", ".yaml", ".yml":
		fmt.Fprintf(&buf, "# üì¶ generated by copyrc. DO NOT EDIT.\n")
		fmt.Fprintf(&buf, "# üîó source: %s\n", permalink)
		fmt.Fprintf(&buf, "# ‚ÑπÔ∏è see .copyrc.lock for more details.\n\n")
	case ".md", ".xml":
		fmt.Fprintf(&buf, "<!--\n")
		fmt.Fprintf(&buf, "üì¶ generated by copyrc. DO NOT EDIT.\n")
		fmt.Fprintf(&buf, "üîó source: %s\n", permalink)
		fmt.Fprintf(&buf, "‚ÑπÔ∏è see .copyrc.lock for more details.\n")
		fmt.Fprintf(&buf, "-->\n\n")
	}

	// Write original content
	buf.Write(contentz)

	// Apply replacements
	var replacementCount int
	for _, r := range cfg.CopyArgs.Replacements {
		if r.File != nil && *r.File != "" {
			matched, err := doublestar.Match(*r.File, file)
			if err != nil {
				return errors.Errorf("matching file: %w", err)
			}
			if !matched {
				continue
			}
		}
		if bytes.Contains(buf.Bytes(), []byte(r.Old)) {
			// Count occurrences of the replacement
			replacementCount += bytes.Count(buf.Bytes(), []byte(r.Old))

			// Find line numbers for the changes
			lines := bytes.Split(buf.Bytes(), []byte("\n"))
			for i, line := range lines {
				if bytes.Contains(line, []byte(r.Old)) {
					change := fmt.Sprintf("Line %d: Replaced '%s' with '%s'", i+1, r.Old, r.New)
					entry.Changes = append(entry.Changes, change)
				}
			}

			// Apply the replacement
			newContent := bytes.ReplaceAll(buf.Bytes(), []byte(r.Old), []byte(r.New))
			buf.Reset()
			buf.Write(newContent)
		}
	}

	// Check if file exists and has .patch suffix
	outPath := filepath.Join(cfg.DestPath, entry.File)

	mu.Lock()
	_, hasOldStatus := status.CoppiedFiles[entry.File]
	mu.Unlock()

	currFile, err := os.ReadFile(outPath)
	// if the current and new file are the same, skip
	if err == nil && bytes.Equal(currFile, buf.Bytes()) && hasOldStatus {
		entry.LastUpdated = status.CoppiedFiles[entry.File].LastUpdated
		logFileOperation(logger, entry.File, RegularFile, replacementCount)
	} else if os.IsNotExist(err) {
		if err := os.WriteFile(outPath, buf.Bytes(), 0644); err != nil {
			return errors.Errorf("writing file: %w", err)
		}
		logFileOperation(logger, entry.File, NewFile, replacementCount)
	} else {
		if err := os.WriteFile(outPath, buf.Bytes(), 0644); err != nil {
			return errors.Errorf("writing file: %w", err)
		}
		logFileOperation(logger, entry.File, UpdatedFile, replacementCount)
	}

	// Update status file (with mutex for concurrent access)
	mu.Lock()
	status.CoppiedFiles[entry.File] = entry
	mu.Unlock()

	return nil
}

func processDirectory(ctx context.Context, provider RepoProvider, cfg *Config, commitHash string, status *StatusFile, mu *sync.Mutex) error {
	logger := NewLogger(os.Stdout)

	// Get list of files from provider
	files, err := provider.ListFiles(ctx, cfg.ProviderArgs)
	if err != nil {
		return errors.Errorf("listing files: %w", err)
	}

	// Sort files by name
	sort.Strings(files)

	// Add untracked files from local directory
	if cfg.DestPath != "" {
		var dirPath string
		if cfg.ArchiveArgs != nil {
			dirPath = filepath.Join(cfg.DestPath, filepath.Base(cfg.ProviderArgs.Repo))
		} else {
			dirPath = cfg.DestPath
		}

		entries, err := os.ReadDir(dirPath)
		if err == nil {
			// Sort entries by name
			sortedEntries := make([]os.DirEntry, len(entries))
			copy(sortedEntries, entries)
			sort.Slice(sortedEntries, func(i, j int) bool {
				return sortedEntries[i].Name() < sortedEntries[j].Name()
			})

			for _, entry := range sortedEntries {
				if !entry.IsDir() {
					name := entry.Name()
					// Show .copyrc.lock files and untracked .go files
					if strings.HasSuffix(name, ".copyrc.lock") {
						logFileOperation(logger, name, SpecialFile, 0)
					} else if strings.HasSuffix(name, ".go") && !strings.HasSuffix(name, ".copy.go") && name != "embed.gen.go" {
						logFileOperation(logger, name, UntrackedFile, 0)
					}
				}
			}
		}
	}

	// Process each file
	if cfg.Async {
		var wg sync.WaitGroup
		errChan := make(chan error, len(files))

		for _, file := range files {
			wg.Add(1)
			go func(f string) {
				defer wg.Done()
				if err := processFile(ctx, provider, cfg, f, commitHash, status, mu); err != nil {
					errChan <- errors.Errorf("processing file %s: %w", f, err)
				}
			}(file)
		}

		// Wait for all goroutines to finish
		wg.Wait()
		close(errChan)

		// Check for errors
		for err := range errChan {
			if err != nil {
				return err
			}
		}
	} else {
		for _, file := range files {
			if file == "" {
				continue
			}
			if err := processFile(ctx, provider, cfg, file, commitHash, status, mu); err != nil {
				return errors.Errorf("processing file %s: %w", file, err)
			}
		}
	}

	// Add existing files from status
	if status != nil {
		for name := range status.CoppiedFiles {
			if _, exists := processedFiles.Load(name); !exists {
				logFileOperation(logger, name, RegularFile, 0)
			}
		}
		for name := range status.GeneratedFiles {
			if _, exists := processedFiles.Load(name); !exists {
				logFileOperation(logger, name, RegularFile, 0)
			}
		}
	}

	return nil
}
